---
title: "Multivariable Regression Examples"
output:
    html_document:
        keep_md: true
---

```{r setup, cache=FALSE, echo=FALSE, message=F, warning=F, tidy=FALSE}
require(knitr)
options(width=100)
opts_chunk$set(message=F, error=F, warning=F, comment=NA, fig.align='center', dpi=100, tidy=F, cache.path='.cache/', fig.path='fig/')

options(xtable.type='html')
knit_hooks$set(inline=function(x) {
    if(is.numeric(x)) {
        round(x, getOptions('digits'))
    } else {
        paste(as.character(x), collapse=', ')
    }
})
knit_hooks$set(plot=knitr:::hook_plot_html)
```

## Dataset for Discussion

#### `require(datasets); data(swiss); ?swiss`

Standardized fertility measure and socio-economic indicators for each of 47 French-speaking provinces of Switzerland at about 1888.

A data frame with 47 observations on 6 variables, each of which is in percent, i.e., in [0, 100].

- [,1] Fertility - a common standardized fertility measure
- [,2] Agriculture - % of males involved in agriculture as occupation
- [,3] Examination - % draftees receiving highest mark on army examination
- [,4] Education - % education beyond primary school for draftees
- [,5] Catholic - % catholic (as opposed to protestant)
- [,6] Infant.Mortality - live births who live less than 1 year

All variables but `Fertility` give proportions of population.

---

```{r, fig.height=6, fig.width=10, echo=FALSE}
require(datasets)
require(GGally)
require(ggplot2)
data(swiss)
ggpairs(swiss, lower=list(continuous="smooth"), params=c(method="loess"))
```

---

## Calling `lm`

```{r}
summary(lm(Fertility ~ ., data=swiss))$coefficients
```

---

## Example Interpretation

- Agriculture is expressed in percentages (0 - 100)
- Estimate is -0.1721
- Our models estimates an expected 0.17 decrease in standardized fertility for every 1% increase in percentage of males involved in agriculture in holding the remaining variables constant.
- The $t$-test for $H_0 : \beta_{Agri} = 0$ versus $H_\alpha : \beta_{Agri} \ne 0$ is significant
- Interestingly, the unadjusted estimate is

```{r}
summary(lm(Fertility ~ Agriculture, data=swiss))$coefficients
```

---

How can adjustment reverse the sign of an effect? Let's try a simulation.

```{r}
n <- 100
x2 <- 1:n
x1 <- .01 * x2 + runif(n, -.1, .1)
y <- -x1 + x2 + rnorm(n, sd=.01)
summary(lm(y ~ x1))$coefficients
summary(lm(y ~ x1 + x2))$coefficients
```

---

```{r, echo=FALSE, fig.height=5, fig.width=10, results='show'}
dat <- data.frame(y=y, x1=x1, x2=x2, ey=resid(lm(y ~ x2)), ex1=resid(lm(x1 ~ x2)))
ggplot(dat, aes(y=y, x=x1, color=x2)) +
    geom_point(color="grey50", size=5) +
    geom_smooth(method="lm", se=F, color="black") +
    geom_point(size=4)
```

---

```{r, echo=FALSE, fig.height=5, fig.width=10, results='show'}
ggplot(dat, aes(y=ey, x=ex1, color=x2)) +
    geom_point(color="grey50", size=5) +
    geom_smooth(method="lm", se=F, color="black") +
    geom_point(size=4)
```

---

## Back to This Dataset

- The sign reverses itself with the inclusion of `Examination` and `Education`
- The percent of males in the province working in agriculture is negatively related to educational attainment (correlation of -0.6395) and `Education` and `Examination` (correlation of 0.6984) are obviously measuring similar things
    - Is the positive marginal an artifact for not having accounted for, say, `Education` level? (`Education` does have a stronger effect, by the way)
- At the minimum, anyone claiming that provinces that are more agricultural have higher fertility rates would immediately be open to criticism

---

## What If We Include an Unnecessary Value?

`z` adds no new linear information, since it's a linear combination of variables already included. R just drops terms that are linear combinations of other terms.

```{r}
z <- swiss$Agriculture + swiss$Education
lm(Fertility ~ . + z, swiss)
```

---

## Dummy Variables Are Smart

- Consider the linear model
$$
Y_i = \beta_0 + X_{1i}\beta_1 + \epsilon_i
$$
where each $X_{1i} is binary so that it is a 1 if measurement $i$ is in a group and 0 otherwise (treated versus not in a clinical trial, for example)
- Then for people in the group $E\left[Y_i\right] = \beta_0 + \beta_1$
- And for people not in the group $E\left[Y_i\right] = \beta_0$
- The LS fits work out to be $\hat\beta_0 + \hat\beta_1$ is the mean for those in the group and $\hat\beta_0$ is the mean for those not in the group
- $\beta_1$ is interpretted as the increase or decrease in the mean comparing those in the group to those not
- Note including a binary variable that is 1 for those not in the group would be redundant. it would create three parameters to describe two means

---

## More Than 2 Levels

- Consider a multilevel factor variable. For didactic reasons, let's say a three level factor (example, US political party affiliation: Republican, Democrat, Independent)
- $Y_i = \beta_0 + X_{1i}\beta_1 + X_{2i}\beta_2 + \epsilon_i$
- $X_{1i}$ is 1 for Republicans and 0 otherwise
- $X_{2i}$ is 1 for Democrats and 0 otherwise
- If $i$ is Republican $E\left[Y_i\right] = \beta_0 + \beta_1$
- If $i$ is Democrat $E\left[Y_i\right] = \beta_0 + \beta_2$
- If $i$ is Independent $E\left[Y_i\right] = \beta_0$
- $\beta_1$ compares Republicans to Independents
- $\beta_2$ compares Democrats to Independents
- $\beta_1 - \beta_2$ compares Republicans to Democrats
- Choice of reference category changes the interpretation

---

## Insect Sprays

```{r, echo=FALSE, fig.height=5, fig.width=5}
require(stats)
data(InsectSprays)
ggplot(InsectSprays, aes(y=count, x=spray, fill=spray)) +
    geom_violin(color="black", size=2) +
    xlab("Type of Spray") +
    ylab("Insect Count")
```

---

## Linear Model Fit, Group A Is the Reference

```{r}
summary(lm(count ~ spray, InsectSprays))$coefficients
```

---

## Hard Coding the Dummy Variables

```{r}
summary(lm(count ~
               I(1 * (spray == 'B')) +
               I(1 * (spray == 'C')) +
               I(1 * (spray == 'D')) +
               I(1 * (spray == 'E')) +
               I(1 * (spray == 'F')),
           InsectSprays))$coefficients
```

---

## What If We Include All 6?

```{r}
summary(lm(count ~
               I(1 * (spray == 'B')) +
               I(1 * (spray == 'C')) +
               I(1 * (spray == 'D')) +
               I(1 * (spray == 'E')) +
               I(1 * (spray == 'F')) +
               I(1 * (spray == 'A')),
           InsectSprays))$coefficients
```

---

## What If We Omit the Intercept?

```{r}
require(dplyr)
summary(lm(count ~ spray - 1, InsectSprays))$coefficients
summarize(group_by(InsectSprays, spray), mn=mean(count))
```

---

## Reordering the Levels

```{r}
spray2 <- relevel(InsectSprays$spray, "C")
summary(lm(count ~ spray2, InsectSprays))$coefficients
```

---

## Summary

- If we treat Spray as a factor, R includes an intercept and omits the alphabetically first level of the factor
    - All $t$-tests are for comparisons of Sprays versus Spray A
    - Empirical mean for A is the intercept
    - Other group means are the intercept plus their coefficients
- If we omit an intercept, then it includes terms for all levels of the factor
    - Group means are the coefficients
    - Tests are tests of whether the groups are different than zero (Are the expected counts zero for that spray?)
- If we want comparisons between Spray B and C, say, we could refit the model with C (or B) as the reference level

---

## Other Thoughts On This Data

- Counts are bounded from below by 0, violates the assumption of normality of the errors
    - Also there are counts near zero, so both the actual assumption and the intent of the assumption are violated
- Variance does not appear to be constant
- Perhaps taking logs of the counts would help
    - There are 0 counts, so maybe log(Count + 1)
- Also, we'll cover Poisson GLMs for fitting count data

---

## Recall the `swiss` dataset

```{r}
head(swiss)
```

---

## Create a binary variable

```{r}
swiss <- mutate(swiss, CatholicBin = 1 * (Catholic > 50))
```

---

## Plot the Data

```{r, fig.height=5, fig.width=8, echo=F}
g <- ggplot(swiss, aes(x=Agriculture, y=Fertility, color=factor(CatholicBin))) +
    geom_point(size=6, color="black") +
    geom_point(size=4) +
    xlab("% in Agriculture") +
    ylab("Fertility")
g
```

---

## No Effect of Religion

```{r}
fit <- lm(Fertility ~ Agriculture, swiss)
summary(fit)$coefficients
g1 <- g + geom_abline(intercept=coef(fit)[1], slope=coef(fit)[2], size=2)
g1
```

---

## Parallel Lines

```{r}
fit <- lm(Fertility ~ Agriculture + factor(CatholicBin), swiss)
summary(fit)$coefficients
g1 <- g + geom_abline(intercept=coef(fit)[1], slope=coef(fit)[2], size=2)
g1 <- g1 + geom_abline(intercept=coef(fit)[1] + coef(fit)[3], slope=coef(fit)[2], size=2)
g1
```

---

## Lines with Different Slopes and Intercepts

```{r}
fit <- lm(Fertility ~ Agriculture * factor(CatholicBin), swiss)
summary(fit)$coefficients
g1 <- g + geom_abline(intercept=coef(fit)[1], slope=coef(fit)[2], size=2,
                      color="salmon")
g1 <- g1 + geom_abline(intercept=coef(fit)[1] + coef(fit)[3],
                       slope=coef(fit)[2] + coef(fit)[4], size=2,
                       color=hcl(h=195, c=100, l=65))
g1
```

---

## Just to Show You It Can Be Done

```{r}
summary(lm(Fertility ~ Agriculture + Agriculture : factor(CatholicBin), swiss))$coefficients
```